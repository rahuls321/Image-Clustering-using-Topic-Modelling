{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T10:05:16.416695Z",
     "iopub.status.busy": "2022-04-26T10:05:16.415845Z",
     "iopub.status.idle": "2022-04-26T10:05:16.428603Z",
     "shell.execute_reply": "2022-04-26T10:05:16.427466Z",
     "shell.execute_reply.started": "2022-04-26T10:05:16.416654Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import Model,layers\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import shutil\n",
    "\n",
    "# Common data handling libraries\n",
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "# Gensim for LDA\n",
    "import gensim\n",
    "# NLTK for test processing\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# spacy for Lemmatization\n",
    "import spacy\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:39:57.384701Z",
     "iopub.status.busy": "2022-04-26T11:39:57.384378Z",
     "iopub.status.idle": "2022-04-26T11:39:57.390860Z",
     "shell.execute_reply": "2022-04-26T11:39:57.389550Z",
     "shell.execute_reply.started": "2022-04-26T11:39:57.384668Z"
    }
   },
   "outputs": [],
   "source": [
    "data_name = 'flickr8k'\n",
    "\n",
    "if data_name=='flickr8k':\n",
    "    caption_path=\"/kaggle/input/flickr8k/flickr8k/flickr8k/Flickr8k.token.txt\"\n",
    "    img_path='/kaggle/input/flickr8k/flickr8k-images/flickr8k-images/'  \n",
    "elif data_name=='coco':\n",
    "    !mkdir /kaggle/working/coco_datasets\n",
    "else:\n",
    "    print(\"Choose appropriate dataname choices = ['flickr8k', 'coco']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T10:05:17.221519Z",
     "iopub.status.busy": "2022-04-26T10:05:17.221238Z",
     "iopub.status.idle": "2022-04-26T11:32:44.557007Z",
     "shell.execute_reply": "2022-04-26T11:32:44.553412Z",
     "shell.execute_reply.started": "2022-04-26T10:05:17.221487Z"
    }
   },
   "outputs": [],
   "source": [
    "if data_name=='coco':\n",
    "    # !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip -P /kaggle/working\n",
    "    # !unzip /kaggle/working/annotations_trainval2017.zip\n",
    "    !pip install pycocotools\n",
    "    from pycocotools.coco import COCO\n",
    "    import numpy as np\n",
    "    import skimage.io as io\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pylab\n",
    "    # initialize COCO api for instance annotations\n",
    "    coco_caps=COCO('annotations/captions_train2017.json')\n",
    "    img_captions=[]\n",
    "    img_url=[]\n",
    "    img_ids=[]\n",
    "    i=0\n",
    "    import json\n",
    "    # Opening JSON file\n",
    "    f = open('/kaggle/working/annotations/captions_train2017.json')\n",
    "    dd = json.load(f)\n",
    "    for dicti in dd['images']:\n",
    "        annIds = coco_caps.getAnnIds(imgIds=dicti['id'])\n",
    "        anns = coco_caps.loadAnns(annIds)\n",
    "        captions = []\n",
    "        for d in anns:\n",
    "            captions.append(d['caption'])\n",
    "        img_captions.append(' '.join(captions))\n",
    "        img_url.append(dicti['coco_url'])\n",
    "        img_ids.append('/kaggle/working/coco_datasets/'+str(dicti['id'])+'.jpg')\n",
    "        I = io.imread(dicti['coco_url'])\n",
    "        io.imsave('/kaggle/working/coco_datasets/'+str(dicti['id'])+'.jpg', I)\n",
    "        if i==8000: break\n",
    "        if i%500==0: print(i)\n",
    "        i+=1\n",
    "    \n",
    "    img_cap_df = pd.DataFrame({})\n",
    "    img_cap_df['image_id'] = img_ids #img_url[:8000]\n",
    "    img_cap_df['caption'] = img_captions#[:8001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:39:57.396694Z",
     "iopub.status.busy": "2022-04-26T11:39:57.396119Z",
     "iopub.status.idle": "2022-04-26T11:40:02.049108Z",
     "shell.execute_reply": "2022-04-26T11:40:02.048270Z",
     "shell.execute_reply.started": "2022-04-26T11:39:57.396620Z"
    }
   },
   "outputs": [],
   "source": [
    "if data_name=='flickr8k':\n",
    "    with open(caption_path, 'r') as file: \n",
    "        #Read the file data\n",
    "        data = file.read()\n",
    "\n",
    "    image_id_list, caption_list = list(), list()\n",
    "\n",
    "    # Create a list of all image names in the directory\n",
    "    img_file_names_list = glob.glob(img_path+ '*.jpg')  \n",
    "    img_file_names_list = [img_file.replace('\\\\','/') for img_file in img_file_names_list]  \n",
    "    i=0\n",
    "    image_id_dict=[]\n",
    "    #iterate through each line\n",
    "    for line in data.split('\\n'):\n",
    "        #line is empty continue with next line\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        #split the imageid and caption sep by tab\n",
    "        image_id, caption = line.split('\\t')    \n",
    "        #strip the file extension from imageid\n",
    "        image_id = image_id.split('#')[0]\n",
    "        #append the file path to image_id \n",
    "        image_id = os.path.join(img_path, image_id)\n",
    "\n",
    "        if image_id in img_file_names_list:\n",
    "            #store it in list\n",
    "            image_id_list.append(image_id)\n",
    "            caption_list.append(caption)\n",
    "\n",
    "    img_cap_df = pd.DataFrame({'image_id':image_id_list, 'caption':caption_list})\n",
    "    # Group the captions by image_id to form a single sentence for each image\n",
    "    img_cap_df = img_cap_df.groupby('image_id')['caption'].apply(lambda x : ' '.join(x)).reset_index(name='caption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:40:02.057709Z",
     "iopub.status.busy": "2022-04-26T11:40:02.057018Z",
     "iopub.status.idle": "2022-04-26T11:40:02.072650Z",
     "shell.execute_reply": "2022-04-26T11:40:02.071656Z",
     "shell.execute_reply.started": "2022-04-26T11:40:02.057662Z"
    }
   },
   "outputs": [],
   "source": [
    "img_cap_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:40:02.075933Z",
     "iopub.status.busy": "2022-04-26T11:40:02.075395Z",
     "iopub.status.idle": "2022-04-26T11:40:02.089986Z",
     "shell.execute_reply": "2022-04-26T11:40:02.088924Z",
     "shell.execute_reply.started": "2022-04-26T11:40:02.075886Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "img_cap_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:40:02.092735Z",
     "iopub.status.busy": "2022-04-26T11:40:02.092042Z",
     "iopub.status.idle": "2022-04-26T11:41:12.593654Z",
     "shell.execute_reply": "2022-04-26T11:41:12.592708Z",
     "shell.execute_reply.started": "2022-04-26T11:40:02.092695Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(data):\n",
    "\n",
    "    # convert to lower case\n",
    "    data = [word.lower() for word in data.split()]\n",
    "    \n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    # remove punctuation from each word\n",
    "    data = [word.translate(table) for word in data]\n",
    "    \n",
    "    # remove tokens with numbers in them\n",
    "    data = [word for word in data if word.isalpha()]   \n",
    "    \n",
    "    # remove stopwords\n",
    "    data = [word for word in data if word not in nltk.corpus.stopwords.words('english')]\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "data_caption = list(img_cap_df['caption'].apply(lambda x : clean_text(x)))\n",
    "print(data_caption[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:41:12.595172Z",
     "iopub.status.busy": "2022-04-26T11:41:12.594780Z",
     "iopub.status.idle": "2022-04-26T11:41:57.626980Z",
     "shell.execute_reply": "2022-04-26T11:41:57.626103Z",
     "shell.execute_reply.started": "2022-04-26T11:41:12.595143Z"
    }
   },
   "outputs": [],
   "source": [
    "# lemmatize the words\n",
    "nlp = spacy.load(r\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "#nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "data_caption_lemmatized = [[word.lemma_ for word in nlp(str(' '.join(doc))) if word.pos_ in allowed_postags] \n",
    "                           for doc in data_caption]\n",
    "img_cap_df['caption_lemmatized'] = data_caption_lemmatized\n",
    "img_cap_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:41:57.628323Z",
     "iopub.status.busy": "2022-04-26T11:41:57.628104Z",
     "iopub.status.idle": "2022-04-26T11:41:57.639682Z",
     "shell.execute_reply": "2022-04-26T11:41:57.638595Z",
     "shell.execute_reply.started": "2022-04-26T11:41:57.628286Z"
    }
   },
   "outputs": [],
   "source": [
    "# shuffle the DataFrame rows\n",
    "img_cap_df = img_cap_df.sample(frac = 1)\n",
    "# Train, valid, test split of dataset\n",
    "train_df = img_cap_df[:-2000]\n",
    "valid_df = img_cap_df[-2000:-1000]\n",
    "test_df = img_cap_df[-1000:]\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:41:57.641174Z",
     "iopub.status.busy": "2022-04-26T11:41:57.640894Z",
     "iopub.status.idle": "2022-04-26T11:41:58.056586Z",
     "shell.execute_reply": "2022-04-26T11:41:58.055594Z",
     "shell.execute_reply.started": "2022-04-26T11:41:57.641143Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = gensim.corpora.Dictionary(train_df['caption_lemmatized'])\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in train_df['caption_lemmatized']]\n",
    "# View\n",
    "print(corpus[:1])\n",
    "# Human readable format of corpus (term-frequency)\n",
    "print([[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:41:58.058921Z",
     "iopub.status.busy": "2022-04-26T11:41:58.058138Z",
     "iopub.status.idle": "2022-04-26T11:44:10.689015Z",
     "shell.execute_reply": "2022-04-26T11:44:10.686749Z",
     "shell.execute_reply.started": "2022-04-26T11:41:58.058873Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the optimal number of topics\n",
    "START = 10\n",
    "LIMIT = 100\n",
    "STEP = 5\n",
    "topic_range = range(START, LIMIT, STEP)\n",
    "\n",
    "coherence_values = []\n",
    "model_list = []\n",
    "for num_topics in topic_range:\n",
    "    print(num_topics)\n",
    "    model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word, num_topics=num_topics)\n",
    "#     model = gensim.models.LsiModel(corpus=corpus, id2word=id2word, num_topics=num_topics)\n",
    "    model_list.append(model)\n",
    "    coherencemodel = gensim.models.coherencemodel.CoherenceModel(model=model, texts=train_df['caption_lemmatized'], \n",
    "                                                                 dictionary=id2word, coherence='c_v')\n",
    "    coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "max_coherence_val = 0\n",
    "optimal_model = None\n",
    "\n",
    "# Print the coherence scores\n",
    "for i, (m, cv) in enumerate(zip(topic_range, coherence_values)):\n",
    "    if max_coherence_val < round(cv, 4):\n",
    "        optimal_model = model_list[i]\n",
    "        optimal_num_topics = m\n",
    "        max_coherence_val = round(cv, 4)\n",
    "\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))\n",
    "\n",
    "# plot coherence results\n",
    "plt.plot(coherence_values)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:44:10.694430Z",
     "iopub.status.busy": "2022-04-26T11:44:10.693941Z",
     "iopub.status.idle": "2022-04-26T11:44:19.335516Z",
     "shell.execute_reply": "2022-04-26T11:44:19.334521Z",
     "shell.execute_reply.started": "2022-04-26T11:44:10.694393Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "for topic in optimal_model.print_topics():\n",
    "    print(topic)\n",
    "    \n",
    "doc_lda = optimal_model[corpus]\n",
    "print('Optimal Number of Topics :', optimal_num_topics)\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', optimal_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = gensim.models.coherencemodel.CoherenceModel(model=optimal_model, texts=data_caption_lemmatized, \n",
    "                                                                  dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:44:19.337279Z",
     "iopub.status.busy": "2022-04-26T11:44:19.337044Z",
     "iopub.status.idle": "2022-04-26T11:44:19.346747Z",
     "shell.execute_reply": "2022-04-26T11:44:19.345571Z",
     "shell.execute_reply.started": "2022-04-26T11:44:19.337248Z"
    }
   },
   "outputs": [],
   "source": [
    "def predictTopics(corpus, optimal_model):\n",
    "\n",
    "    caption_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(optimal_model[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = optimal_model.show_topic(int(topic_num))\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                caption_topics_df = caption_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), \n",
    "                                                             ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    caption_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "    return caption_topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:44:19.349255Z",
     "iopub.status.busy": "2022-04-26T11:44:19.348316Z",
     "iopub.status.idle": "2022-04-26T11:44:19.365225Z",
     "shell.execute_reply": "2022-04-26T11:44:19.364228Z",
     "shell.execute_reply.started": "2022-04-26T11:44:19.349193Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(num_classes, model_type='vgg16'):\n",
    "    \n",
    "    if model_type=='vgg16':\n",
    "        # # Create model\n",
    "        pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=True, input_shape=(224,224,3))\n",
    "        # pop the last softmax layer \n",
    "        pretrained_model.layers.pop()\n",
    "    elif model_type=='vgg19':\n",
    "        # # Create model\n",
    "        pretrained_model = tf.keras.applications.VGG19(weights='imagenet', include_top=True, input_shape=(224,224,3))\n",
    "        # pop the last softmax layer \n",
    "        pretrained_model.layers.pop()\n",
    "    else:\n",
    "        print(\"Not available\")\n",
    "        \n",
    "    # freezing the remaining layers\n",
    "    for layer in pretrained_model.layers:\n",
    "        layer.trainable = False    \n",
    "\n",
    "    output_model = keras.layers.Dense(2056, activation='tanh')(pretrained_model.layers[-1].output)\n",
    "    output_model = keras.layers.Dropout(0.5)(output_model)\n",
    "    output_model = keras.layers.Dense(1024, activation='tanh')(output_model)\n",
    "    output_model = keras.layers.Dropout(0.5)(output_model)\n",
    "    # output_model = vgg16_model.layers[-1].output\n",
    "    output_model = keras.layers.Dense(num_classes, activation='softmax')(output_model)\n",
    "\n",
    "    caption_model = keras.models.Model(pretrained_model.input, output_model)            \n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "    caption_model.compile(optimizer='adam', loss='categorical_crossentropy') #, metrics=[\"acc\"])\n",
    "#     caption_model.summary()\n",
    "    return caption_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:44:19.367446Z",
     "iopub.status.busy": "2022-04-26T11:44:19.366661Z",
     "iopub.status.idle": "2022-04-26T11:44:19.383088Z",
     "shell.execute_reply": "2022-04-26T11:44:19.382340Z",
     "shell.execute_reply.started": "2022-04-26T11:44:19.367409Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, images_paths, labels, model_type='vgg16', image_dimensions=(224, 224, 3), batch_size=64, shuffle=False):\n",
    "        self.labels       = labels              # array of labels\n",
    "        self.images_paths = images_paths        # array of image paths\n",
    "        self.image_dim = image_dimensions\n",
    "        self.batch_size   = batch_size          # batch size\n",
    "        self.shuffle      = shuffle             # shuffle bool\n",
    "        self.model_type = model_type\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.images_paths) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.images_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # selects indices of data for next batch\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "\n",
    "        # select data and load images\n",
    "        labels = np.array([self.labels[k] for k in indexes])\n",
    "\n",
    "        images = np.array([self.preprocessImageForVGG16(self.images_paths[k], self.model_type) for k in indexes])\n",
    "        \n",
    "        # select data and load images\n",
    "        \n",
    "        return images, labels\n",
    "    \n",
    "    \n",
    "    #customize function used for color convetion\n",
    "    def preprocessImageForVGG16(self, filename, model_type):\n",
    "        # load image\n",
    "        image = keras.preprocessing.image.load_img(filename, target_size=(self.image_dim[0], self.image_dim[1]))\n",
    "        # convert the image pixels to a numpy array\n",
    "        image = keras.preprocessing.image.img_to_array(image)\n",
    "        # prepare the image for the VGG model\n",
    "        if model_type=='vgg16':\n",
    "            image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "        elif model_type=='vgg19':\n",
    "            image = tf.keras.applications.vgg19.preprocess_input(image)\n",
    "        elif model_type=='resnet50':\n",
    "            image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:44:19.385472Z",
     "iopub.status.busy": "2022-04-26T11:44:19.384483Z",
     "iopub.status.idle": "2022-04-26T11:44:19.401335Z",
     "shell.execute_reply": "2022-04-26T11:44:19.400271Z",
     "shell.execute_reply.started": "2022-04-26T11:44:19.385418Z"
    }
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "batch_size = 64\n",
    "nb_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T11:44:19.403650Z",
     "iopub.status.busy": "2022-04-26T11:44:19.402766Z",
     "iopub.status.idle": "2022-04-26T11:53:49.744451Z",
     "shell.execute_reply": "2022-04-26T11:53:49.743000Z",
     "shell.execute_reply.started": "2022-04-26T11:44:19.403616Z"
    }
   },
   "outputs": [],
   "source": [
    "model_type = ['vgg16', 'vgg19']\n",
    "best_bleu_score=-1\n",
    "best_results_df=[]\n",
    "optimal_LDA_model=[]\n",
    "best_pretrained_model=[]\n",
    "best_topic=0\n",
    "best_pretrained_model_name=''\n",
    "topic_model_bleu_score_dict={}\n",
    "\n",
    "!mkdir /kaggle/working/results\n",
    "mode = 0o666\n",
    "topic_choice = (np.arange(10)*10)[3:4]\n",
    "print(\"Topic choice: \", topic_choice)\n",
    "for i, topic in enumerate(topic_range):\n",
    "#     if topic not in topic_choice: continue\n",
    "    print(\"Topic: \", topic)\n",
    "    d_path = '/kaggle/working/results/'+str(topic_range[i])\n",
    "    shutil.rmtree(d_path, ignore_errors=True)\n",
    "    os.mkdir(d_path, mode)\n",
    "    topic_model_bleu_score_dict[topic]={m:0 for m in model_type}\n",
    "    LDA_model = model_list[i]\n",
    "    \n",
    "    train1_df = train_df.copy()\n",
    "    valid1_df = valid_df.copy()\n",
    "    test1_df = test_df.copy()\n",
    "    \n",
    "    df = predictTopics([id2word.doc2bow(text) for text in train1_df['caption_lemmatized']], LDA_model)\n",
    "    train1_df = pd.concat([train1_df.reset_index(drop=True), df], axis=1)\n",
    "\n",
    "    df = predictTopics([id2word.doc2bow(text) for text in valid1_df['caption_lemmatized']], LDA_model)\n",
    "    valid1_df = pd.concat([valid1_df.reset_index(drop=True), df], axis=1)\n",
    "\n",
    "    df = predictTopics([id2word.doc2bow(text) for text in test1_df['caption_lemmatized']], LDA_model)\n",
    "    test1_df = pd.concat([test1_df.reset_index(drop=True), df], axis=1)\n",
    "    \n",
    "    X_train = train1_df['image_id'].values\n",
    "    Y_train1 = train1_df['Dominant_Topic'].values #train_topics #\n",
    "    Y_train = tf.keras.utils.to_categorical(Y_train1, num_classes=topic)\n",
    "\n",
    "    X_valid = valid1_df['image_id'].values\n",
    "    Y_valid1 = valid1_df['Dominant_Topic'].values #val_topics # \n",
    "    Y_valid = tf.keras.utils.to_categorical(Y_valid1, num_classes=topic)\n",
    "    \n",
    "    X_test = test1_df['image_id'].values\n",
    "    Y_test = test1_df['Dominant_Topic'].values #test_topics #\n",
    "    Y_test = tf.keras.utils.to_categorical(Y_test, num_classes=topic)\n",
    "\n",
    "    for mt in model_type:\n",
    "        print(\"Model: \", mt)\n",
    "        model = get_model(topic, mt)\n",
    "        \n",
    "        # prepare data generator\n",
    "        train_data = DataGenerator(X_train, Y_train, model_type=mt, batch_size=batch_size, shuffle=True)\n",
    "        valid_data = DataGenerator(X_valid, Y_valid, model_type=mt, batch_size=batch_size, shuffle=False)\n",
    "        test_data = DataGenerator(X_test, Y_test, model_type=mt, batch_size=1, shuffle=False)\n",
    "        \n",
    "        # Train the model\n",
    "        # reduces learning rate if no improvement are seen\n",
    "        learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=2,verbose=1,factor=0.5,min_lr=0.0000001)\n",
    "        # stop training if no improvements are seen\n",
    "        early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\",mode=\"min\",patience=5)\n",
    "        # saves model weights to file\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint('/kaggle/working/topic_predictor_model.hdf5',\n",
    "                                                     monitor='val_loss',verbose=1,save_best_only=True,mode='min',save_weights_only=True)\n",
    "        history = model.fit_generator(generator=train_data,\n",
    "                                   validation_data=valid_data,\n",
    "                                   epochs=nb_epoch,\n",
    "                                   steps_per_epoch=len(train_data),\n",
    "                                   validation_steps =len(valid_data),\n",
    "                                   callbacks=[learning_rate_reduction, early_stop, checkpoint],\n",
    "                                   verbose=2,\n",
    "                                   )\n",
    "        \n",
    "        # plot training history\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "        ax.plot(history.history['loss'], label=\"TrainLoss\")\n",
    "        ax.plot(history.history['val_loss'], label=\"ValLoss\")\n",
    "        ax.legend(loc='best', shadow=True)\n",
    "        fig.savefig(d_path+\"/Topic_\"+str(topic)+\"_model_\"+mt+\"_fig.png\")\n",
    "\n",
    "        # predict on data\n",
    "        pred_caption_topics_prob = model.predict_generator(test_data)\n",
    "        pred_caption_topics = np.argmax(pred_caption_topics_prob, axis=1)\n",
    "        \n",
    "        pred_words = [list(dict(LDA_model.show_topic(t)).keys()) for t in pred_caption_topics]\n",
    "        ground_truth_words = [list(dict(LDA_model.show_topic(t)).keys()) for t in test1_df['Dominant_Topic'].values.astype(int)]\n",
    "\n",
    "        results_df = pd.DataFrame({ 'image_id':X_test, 'pred_topics':pred_caption_topics, 'ground_truth': test1_df['Dominant_Topic'].values.astype(int), 'pred_topics_words': pred_words, 'ground_truth_words': ground_truth_words})\n",
    "        results_df.to_csv(d_path+\"/Topic_\"+str(topic)+\"_model_\"+mt+\"_df.csv\")\n",
    "        hypothesis = [list(dict(LDA_model.show_topic(gd_topic)).keys()) for gd_topic in results_df['ground_truth'].values]\n",
    "        references = [list(dict(LDA_model.show_topic(pred_topic)).keys()) for pred_topic in results_df['pred_topics'].values]\n",
    "        bleu_score = [sentence_bleu([ref], hyp) for ref, hyp in zip(references, hypothesis)]\n",
    "        mean_bleu_score = np.mean(bleu_score)\n",
    "        topic_model_bleu_score_dict[topic][mt] = mean_bleu_score\n",
    "        print(\"BLEU={:4.3f}\".format(mean_bleu_score))\n",
    "        if mean_bleu_score > best_bleu_score:\n",
    "            best_bleu_score = mean_bleu_score\n",
    "            best_results_df = results_df\n",
    "            optimal_LDA_model=LDA_model\n",
    "            best_pretrained_model=model\n",
    "            best_pretrained_model_name=mt\n",
    "            best_topic=topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-26T11:53:49.745623Z",
     "iopub.status.idle": "2022-04-26T11:53:49.745988Z",
     "shell.execute_reply": "2022-04-26T11:53:49.745807Z",
     "shell.execute_reply.started": "2022-04-26T11:53:49.745787Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"best_bleu_score: \", best_bleu_score)\n",
    "print(\"best_pretrained_model_name: \", best_pretrained_model_name)\n",
    "print(\"best_no_topic: \", best_topic)\n",
    "best_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-26T11:53:49.747466Z",
     "iopub.status.idle": "2022-04-26T11:53:49.748249Z",
     "shell.execute_reply": "2022-04-26T11:53:49.748060Z",
     "shell.execute_reply.started": "2022-04-26T11:53:49.748039Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_model_bleu_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-26T11:53:49.749139Z",
     "iopub.status.idle": "2022-04-26T11:53:49.749708Z",
     "shell.execute_reply": "2022-04-26T11:53:49.749531Z",
     "shell.execute_reply.started": "2022-04-26T11:53:49.749512Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/topics_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-26T11:53:49.750865Z",
     "iopub.status.idle": "2022-04-26T11:53:49.751525Z",
     "shell.execute_reply": "2022-04-26T11:53:49.751336Z",
     "shell.execute_reply.started": "2022-04-26T11:53:49.751313Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "for i, optimal_lda_model in enumerate(model_list):\n",
    "    mode = 0o666\n",
    "    if topic_range[i]%10!=0: continue\n",
    "    d_path = '/kaggle/working/results/'+str(topic_range[i])+'/topics_cloud/'\n",
    "    shutil.rmtree(d_path, ignore_errors=True)\n",
    "    os.mkdir(d_path, mode)\n",
    "    for t in range(optimal_lda_model.num_topics):\n",
    "        plt.figure()\n",
    "        plt.imshow(WordCloud().fit_words(dict(optimal_lda_model.show_topic(t))))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Topic #\" + str(t))\n",
    "#         plt.show()\n",
    "        plt.savefig('/kaggle/working/results/'+str(topic_range[i])+'/topics_cloud'+'/t'+str(t)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-26T11:53:49.752546Z",
     "iopub.status.idle": "2022-04-26T11:53:49.753199Z",
     "shell.execute_reply": "2022-04-26T11:53:49.753008Z",
     "shell.execute_reply.started": "2022-04-26T11:53:49.752978Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "# shutil.make_archive('vgg16_vgg_19_topics', 'zip', '/kaggle/working/topics_cloud')\n",
    "shutil.make_archive('results', 'zip', '/kaggle/working/results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T12:24:11.663287Z",
     "iopub.status.busy": "2022-04-26T12:24:11.662979Z",
     "iopub.status.idle": "2022-04-26T12:24:11.742621Z",
     "shell.execute_reply": "2022-04-26T12:24:11.741589Z",
     "shell.execute_reply.started": "2022-04-26T12:24:11.663254Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open('/kaggle/input/flickr8k/flickr8k-images/flickr8k-images/3375991133_87d7c40925.jpg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-26T11:53:49.757800Z",
     "iopub.status.idle": "2022-04-26T11:53:49.758175Z",
     "shell.execute_reply": "2022-04-26T11:53:49.758002Z",
     "shell.execute_reply.started": "2022-04-26T11:53:49.757954Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install wordcloud\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T12:25:45.009633Z",
     "iopub.status.busy": "2022-04-26T12:25:45.009358Z",
     "iopub.status.idle": "2022-04-26T12:25:45.562809Z",
     "shell.execute_reply": "2022-04-26T12:25:45.561862Z",
     "shell.execute_reply.started": "2022-04-26T12:25:45.009602Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot training history\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(WordCloud().fit_words(dict(model_list[11].show_topic(54))))\n",
    "# ax.legend(loc='best', shadow=True)\n",
    "# fig.savefig(d_path+\"/Topic_\"+str(topic)+\"_model_\"+mt+\"_fig.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
